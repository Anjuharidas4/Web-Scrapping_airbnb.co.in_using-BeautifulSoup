

from bs4 import BeautifulSoup

import lxml

import requests

import pandas as pd

url = "https://www.airbnb.co.in/s/Honolulu--HI--United-States/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&flexible_trip_lengths%5B%5D=one_week&price_filter_input_type=0&price_filter_num_nights=2&channel=EXPLORE&search_type=category_change&query=Honolulu%2C%20HI&place_id=ChIJTUbDjDsYAHwRbJen81_1KEs&date_picker_type=calendar&checkin=2023-03-16&checkout=2023-03-18&source=structured_search_input_header&location_search=MIN_MAP_BOUNDS"

page = requests.get(url)

soup = BeautifulSoup(page.text,"lxml")

df = pd.DataFrame({"Link":[''],"Title":[''],"Sub_Title":[''],"Bed":[''],"Price":[''],"Rating":['']})


while True:
    posting = soup.find_all("div",class_="c4mnd7m dir dir-ltr")
    for post in posting:
        try:
            link = post.find("a",class_= "l1j9v1wn bn2bl2p dir dir-ltr").get("href")
            link_full = "https://www.airbnb.co.in" + link
            title = post.find("div",class_="t1jojoys dir dir-ltr").text
            title2 = post.find("span",class_="t6mzqp7 dir dir-ltr").text
            bed = post.find("span",class_="dir dir-ltr").text
            price = post.find("span",class_="a8jt5op dir dir-ltr").text
            rating = post.find("span",class_="t5eq1io r4a59j5 dir dir-ltr").get("aria-label")
            df = df.append({"Link":link_full,"Title":title,"Sub_Title":title2,
                            "Bed":bed,"Price":price,"Rating":rating},ignore_index = True)
        except:
            pass
      
    try:     
        next_page = soup.find("a",{"aria-label":"Next"}).get('href') 
        next_page_full = "https://www.airbnb.co.in" + next_page
        next_page_full
        url = next_page_full
        page = requests.get(url)
        soup = BeautifulSoup(page.text,"lxml")
    except:
        break
    

df.to_csv("airbnb.csv")